#!/usr/bin/env python3
"""
VOACAP Quality-of-Prediction Test — Option 4
=============================================

Runs VOACAP predictions for 100K high-confidence WSPR signatures and stores
results in ClickHouse for head-to-head Pearson r / RMSE comparison with IONIS.

Reads:  validation.quality_test_paths  (100K signatures, 10K per band)
Writes: validation.quality_test_voacap (VOACAP predicted SNR per path)

The companion IONIS predictions are generated by Claude-M3 on the Mac Studio.
Both are compared against median_snr (ground truth) in quality_test_paths.

Usage:
    python voacap_quality_test.py [--workers 32] [--host localhost]
                                   [--sample 1000] [--dry-run]
"""

import argparse
import csv
import io
import os
import re
import shutil
import subprocess
import sys
import time
from collections import defaultdict
from concurrent.futures import ProcessPoolExecutor, as_completed
from pathlib import Path

# ---------------------------------------------------------------------------
# Constants
# ---------------------------------------------------------------------------

VOACAPL_BIN = "/usr/local/bin/voacapl"
ITSHFBC_DIR = Path.home() / "itshfbc"

# VOACAP card template — single frequency, 24 hours, Method 30
# Antenna: const17.voa (17 dBi omni)
# TX power: 0.2W (WSPR typical) = 0.0002 kW
CARD_TEMPLATE = """\
LINEMAX      55       number of lines-per-page
COEFFS    CCIR
TIME          1   24    1    1
MONTH      {year:4d} {month:.2f}
SUNSPOT    {ssn:.0f}.
LABEL     QUALTEST                VOACAP
CIRCUIT   {tx_lat}   {tx_lon}    {rx_lat}    {rx_lon}  S     0
SYSTEM       1. 145. 0.10  90. 73.0 3.00 0.10
FPROB      1.00 1.00 1.00 0.00
ANTENNA       1    1    2   30     0.000[default/const17.voa  ]  0.0    0.0002
ANTENNA       2    2    2   30     0.000[default/const17.voa  ]  0.0    0.0002
FREQUENCY {freq:5.2f} 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00
METHOD       30    0
EXECUTE
QUIT
"""

# VOACAP output parsing: offsets from FREQ line
OFFSET_MUFDAY = 6
OFFSET_SNR = 11
OFFSET_REL = 13

# Regex for FREQ lines
FREQ_LINE_RE = re.compile(r"^\s+(\d+\.\d)\s+.*FREQ\s*$")


# ---------------------------------------------------------------------------
# Coordinate formatting
# ---------------------------------------------------------------------------

def fmt_lat(lat: float) -> str:
    hemi = "N" if lat >= 0 else "S"
    return f"{abs(lat):5.2f}{hemi}"


def fmt_lon(lon: float) -> str:
    hemi = "E" if lon >= 0 else "W"
    return f"{abs(lon):6.2f}{hemi}"


# ---------------------------------------------------------------------------
# Circuit key — groups paths that share the same VOACAP card
# ---------------------------------------------------------------------------

def circuit_key(row: dict) -> tuple:
    """Rows sharing a circuit key differ only by hour (VOACAP computes all 24)."""
    return (
        round(float(row["tx_lat"]), 2),
        round(float(row["tx_lon"]), 2),
        round(float(row["rx_lat"]), 2),
        round(float(row["rx_lon"]), 2),
        round(float(row["freq_mhz"]), 2),
        int(row["month"]),
        round(float(row["ssn"]), 0),
    )


# ---------------------------------------------------------------------------
# Card generation
# ---------------------------------------------------------------------------

def generate_card(key: tuple) -> str:
    tx_lat, tx_lon, rx_lat, rx_lon, freq_mhz, month, ssn = key
    # Use 2024 as representative year (VOACAP uses SSN, not year)
    return CARD_TEMPLATE.format(
        year=2024,
        month=float(month),
        ssn=ssn,
        tx_lat=fmt_lat(tx_lat),
        tx_lon=fmt_lon(tx_lon),
        rx_lat=fmt_lat(rx_lat),
        rx_lon=fmt_lon(rx_lon),
        freq=freq_mhz,
    )


# ---------------------------------------------------------------------------
# Output parsing
# ---------------------------------------------------------------------------

def parse_voacap_output(output_text: str) -> dict:
    """Parse Method 30 output -> {hour_utc: (snr, rel, mufday)}."""
    lines = output_text.split("\n")
    results = {}

    for i, line in enumerate(lines):
        m = FREQ_LINE_RE.match(line)
        if not m:
            continue

        hour_voacap = int(float(m.group(1)))  # 1-24
        hour_utc = hour_voacap - 1  # convert to 0-23

        snr = _parse_field(lines, i, OFFSET_SNR)
        rel = _parse_field(lines, i, OFFSET_REL)
        mufday = _parse_field(lines, i, OFFSET_MUFDAY)

        results[hour_utc] = (snr, rel, mufday)

    return results


def _parse_field(lines: list, freq_idx: int, offset: int) -> float:
    idx = freq_idx + offset
    if idx >= len(lines):
        return -999.0
    parts = lines[idx].split()
    if len(parts) < 3:
        return -999.0
    val = parts[1]  # Second value = our requested frequency
    if val == "-":
        return -999.0
    try:
        return float(val)
    except ValueError:
        return -999.0


# ---------------------------------------------------------------------------
# Worker setup
# ---------------------------------------------------------------------------

def setup_worker_dirs(base_dir: Path, n_workers: int) -> list:
    worker_dirs = []
    base_dir.mkdir(parents=True, exist_ok=True)

    for wid in range(n_workers):
        wdir = base_dir / f"worker_{wid:03d}"
        itshfbc = wdir / "itshfbc"

        if itshfbc.exists():
            shutil.rmtree(itshfbc)
        itshfbc.mkdir(parents=True)

        # Symlink large read-only dirs
        for name in ("coeffs", "antennas", "areadata", "area_inv",
                      "geocity", "geonatio", "geostate"):
            src = ITSHFBC_DIR / name
            if src.exists():
                (itshfbc / name).symlink_to(src.resolve())

        # Copy writable dirs
        for name in ("run", "database"):
            src = ITSHFBC_DIR / name
            if src.exists():
                shutil.copytree(src, itshfbc / name)

        # Remove stale output
        for stale in (itshfbc / "run").glob("*.out"):
            stale.unlink()

        worker_dirs.append(itshfbc)

    return worker_dirs


def cleanup_worker_dirs(base_dir: Path):
    if base_dir.exists():
        shutil.rmtree(base_dir)


# ---------------------------------------------------------------------------
# Single circuit runner (called in worker process)
# ---------------------------------------------------------------------------

def run_single_circuit(args: tuple) -> tuple:
    """Run voacapl for one circuit. Returns (circuit_key, hour_results)."""
    key, card_text, worker_dir = args

    input_path = worker_dir / "run" / "voacapx.dat"
    output_path = worker_dir / "run" / "voacapx.out"

    try:
        input_path.write_text(card_text)
        result = subprocess.run(
            [VOACAPL_BIN, str(worker_dir), "voacapx.dat", "voacapx.out"],
            capture_output=True, text=True, timeout=10,
        )

        if result.returncode != 0:
            return (key, None)
        if not output_path.exists():
            return (key, None)

        output_text = output_path.read_text()
        hour_results = parse_voacap_output(output_text)
        return (key, hour_results)

    except Exception:
        return (key, None)


# ---------------------------------------------------------------------------
# ClickHouse I/O
# ---------------------------------------------------------------------------

def load_paths(host: str, port: int, sample: int = 0) -> list:
    """Load paths from validation.quality_test_paths."""
    query = "SELECT * FROM validation.quality_test_paths"
    if sample > 0:
        query += f" LIMIT {sample}"
    query += " FORMAT CSVWithNames"

    result = subprocess.run(
        ["clickhouse-client", f"--host={host}", f"--port={port}", f"--query={query}"],
        capture_output=True, text=True, timeout=120,
    )
    if result.returncode != 0:
        print(f"ERROR: {result.stderr.strip()}", file=sys.stderr)
        sys.exit(1)

    reader = csv.DictReader(io.StringIO(result.stdout))
    return list(reader)


def insert_results(host: str, port: int, rows: list, batch_size: int = 50000):
    """INSERT results into validation.quality_test_voacap."""
    if not rows:
        return

    columns = ["path_id", "voacap_snr", "voacap_rel", "voacap_mufday"]
    total = len(rows)
    inserted = 0

    for batch_start in range(0, total, batch_size):
        batch = rows[batch_start:batch_start + batch_size]
        tsv_lines = []
        for r in batch:
            tsv_lines.append("\t".join(str(r[c]) for c in columns))
        tsv_data = "\n".join(tsv_lines) + "\n"

        col_list = ", ".join(columns)
        query = f"INSERT INTO validation.quality_test_voacap ({col_list}) FORMAT TSV"

        result = subprocess.run(
            ["clickhouse-client", f"--host={host}", f"--port={port}", f"--query={query}"],
            input=tsv_data, capture_output=True, text=True, timeout=120,
        )
        if result.returncode != 0:
            print(f"ERROR inserting batch at offset {batch_start}: "
                  f"{result.stderr.strip()}", file=sys.stderr)
        else:
            inserted += len(batch)

    print(f"Inserted {inserted:,} / {total:,} rows into validation.quality_test_voacap")


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(
        description="VOACAP quality-of-prediction test (Option 4)")
    parser.add_argument("--workers", type=int, default=32,
                        help="Parallel workers (default: 32)")
    parser.add_argument("--host", default="localhost",
                        help="ClickHouse host (default: localhost)")
    parser.add_argument("--port", type=int, default=9000,
                        help="ClickHouse native port (default: 9000)")
    parser.add_argument("--sample", type=int, default=0,
                        help="Process only N rows (0 = all)")
    parser.add_argument("--dry-run", action="store_true",
                        help="Run VOACAP but don't INSERT")
    parser.add_argument("--work-dir", default="/tmp/voacap_quality_work",
                        help="Worker directory base")
    args = parser.parse_args()

    work_dir = Path(args.work_dir)

    # 1. Load paths
    print(f"Loading paths from validation.quality_test_paths "
          f"({args.host}:{args.port})...")
    rows = load_paths(args.host, args.port, args.sample)
    print(f"  Loaded {len(rows):,} paths")

    if not rows:
        print("No rows to process.")
        return

    # 2. Group by unique circuit
    circuits = defaultdict(list)  # circuit_key -> [(row_idx, hour)]
    for idx, row in enumerate(rows):
        key = circuit_key(row)
        circuits[key].append((idx, int(row["hour"])))

    print(f"  Unique circuits: {len(circuits):,} "
          f"(dedup ratio: {len(rows)/len(circuits):.2f}x)")

    # 3. Set up worker directories
    print(f"Setting up {args.workers} worker directories in {work_dir}...")
    worker_dirs = setup_worker_dirs(work_dir, args.workers)

    # 4. Generate cards
    circuit_keys = list(circuits.keys())
    tasks = []
    for i, key in enumerate(circuit_keys):
        card = generate_card(key)
        wdir = worker_dirs[i % args.workers]
        tasks.append((key, card, wdir))

    print(f"  Generated {len(tasks):,} VOACAP input cards")

    # 5. Run voacapl in parallel
    print(f"Running voacapl with {args.workers} workers...")
    t0 = time.time()

    circuit_results = {}
    errors = 0
    completed = 0

    with ProcessPoolExecutor(max_workers=args.workers) as pool:
        futures = {pool.submit(run_single_circuit, t): t[0] for t in tasks}

        for future in as_completed(futures):
            key, hour_data = future.result()
            completed += 1
            if hour_data is None:
                errors += 1
            else:
                circuit_results[key] = hour_data

            if completed % 5000 == 0 or completed == len(tasks):
                elapsed = time.time() - t0
                rate = completed / elapsed if elapsed > 0 else 0
                print(f"\r  Progress: {completed:,}/{len(tasks):,} "
                      f"({completed/len(tasks)*100:.1f}%) "
                      f"| {rate:.0f} circuits/s "
                      f"| errors: {errors:,}", end="", flush=True)

    elapsed = time.time() - t0
    print(f"\n  Completed in {elapsed:.1f}s "
          f"({len(tasks)/elapsed:.0f} circuits/s, {errors:,} errors)")

    # 6. Join results back to original rows
    print("Joining VOACAP results to original rows...")
    output_rows = []
    missing = 0

    for idx, row in enumerate(rows):
        key = circuit_key(row)
        hour_utc = int(row["hour"])
        path_id = int(row["path_id"])

        hour_data = circuit_results.get(key)
        if hour_data is None or hour_utc not in hour_data:
            missing += 1
            snr, rel, mufday = -999.0, 0.0, 0.0
        else:
            snr, rel, mufday = hour_data[hour_utc]

        output_rows.append({
            "path_id": path_id,
            "voacap_snr": round(snr, 2),
            "voacap_rel": round(rel, 4),
            "voacap_mufday": round(mufday, 4),
        })

    valid = sum(1 for r in output_rows if r["voacap_snr"] > -999.0)
    print(f"  Joined {len(output_rows):,} rows "
          f"({valid:,} valid, {missing:,} missing)")

    # 7. INSERT into ClickHouse
    if not args.dry_run:
        print(f"\nInserting results into validation.quality_test_voacap...")
        insert_results(args.host, args.port, output_rows)
    else:
        print("\n[DRY RUN] Skipping ClickHouse INSERT")

    # 8. Quick stats
    valid_rows = [r for r in output_rows if r["voacap_snr"] > -999.0]
    if valid_rows:
        snrs = [r["voacap_snr"] for r in valid_rows]
        avg_snr = sum(snrs) / len(snrs)
        print(f"\n  VOACAP Stats:")
        print(f"    Valid predictions: {len(valid_rows):,} / {len(output_rows):,}")
        print(f"    Mean predicted SNR: {avg_snr:.2f} dB")
        print(f"    Min/Max SNR: {min(snrs):.1f} / {max(snrs):.1f} dB")

    # 9. Cleanup
    print("\nCleaning up worker directories...")
    cleanup_worker_dirs(work_dir)
    print("Done.")


if __name__ == "__main__":
    main()
