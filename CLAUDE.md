# Claude Code Instructions

## Project

**ki7mt-ai-lab-training** — IONIS V2 (Ionospheric Neural Inference System) WSPR propagation prediction model training.

PyTorch neural network trained on WSPR (Weak Signal Propagation Reporter) spot data
joined with solar indices from ClickHouse to predict HF radio signal-to-noise ratio.

## Branding
We are branding this

>IONIS (Ionospheric Neural Inference System): Sounds professional, clean, and describes exactly what the architecture does.

All models and scripts have been refactored with this branding:
```
./models/ionis_v2.pth

# Formal model example
ionis-v2:latest
```

## Repo structure
Use this layout for the repo
```
ki7mt-ai-lab-training/
├── models/
│   └── ionis_v2.pth         # The "Production" weights
├── scripts/
│   ├── train_v2_pilot.py    # Training logic
│   └── test_v2_sensitivity.py # Physics checks
└── results/                 # (New folder) for sensitivity logs
```

## Architecture

- **Model**: ResidualBlock network (2 blocks, 256-unit hidden, BatchNorm + skip connections)
- **Data source**: ClickHouse on 192.168.1.90 (`wspr.spots_raw` + `solar.indices_raw`)
- **Training hardware**: M3 Ultra Mac Studio (MPS backend)
- **Features**: 13 inputs (path geometry, frequency, solar, geography, interactions)

## Key Files

- `scripts/train_v2_pilot.py` — Training script (queries ClickHouse, builds features, trains model)
- `scripts/test_v2_sensitivity.py` — Sensitivity analysis (loads saved model, sweeps parameters)
- `models/ionis_v2.pth` — Saved model checkpoint (not committed, generated by training)

## Phase History

### Phase 1: Consolidation (COMPLETE)
- Resolved "Silent Sun" bug, Physics Gap, Blackwell driver mismatch
- Gold Standard dataset: `wspr.training_set_v1` (6M rows)

### Phase 2: Pilot Training (COMPLETE)
- V2.0: 11 features, 10M rows, RMSE 8.04 dB — inverted SSN response
- V2.1: 13 features, hash-ordered sampling, SSN-SNR r=+0.0143
- **Finding**: Data quality is the bottleneck (leaked bands 14%, SNR -99 to +60, ground-wave contamination)

### Phase 3: Data Purge (COMPLETE)
- SQL filters: `snr[-35,25]`, `band[1,15]`, `distance[500,18000]`
- Target: SSN-SNR Pearson correlation > 0.1

### Phase 3.5: Stratified Band Sampling (BLOCKED — awaiting re-ingest)
- UNION ALL stratified query works but exposed **band encoding bug**
- Root cause: Python ingester stored raw CSV band column (leaked MHz values as band IDs)
- Bands 4 (40m), 6 (20m), 8 (15m) had <1,100 rows each — data was mislabeled, not missing
- Band 14 (2.19B rows) = actually 20m; Band 21 (331M rows) = actually 15m; etc.
- **Fix applied**: All 5 Go CSV ingesters now call `bands.GetBand(freqMHz)` (single source of truth)
- **New band IDs after re-ingest**: 102=160m, 103=80m, 104=60m, 105=40m, 106=30m, 107=20m, 108=17m, 109=15m, 110=12m, 111=10m
- **Next**: Re-ingest on 9975WX, then update BAND_TO_HZ and SQL filters in training script
- Best RMSE so far: 7.22 dB (HF-only, unbalanced), 7.62 dB (stratified but sparse)
- SSN-SNR correlation: +0.0048 (positive but below 0.1 target — needs balanced 20m/40m data)

## Data Quality Notes

- `wspr.spots_raw.band` column contains leaked frequency values (MHz/kHz) for ~14% of raw rows
- `solar.indices_raw` only has SSN with meaningful 2020-2025 coverage (kp: 23 rows, sfi: 0, xray: 2026-01-27+ only)
- FixedString(8) grid values from ClickHouse require null-byte stripping and regex validation
- Band IDs 1-15 are standard ADIF codes; values outside this range are data quality issues

## Conventions

- Feature normalization constants are hardcoded (distance/20000, freq_log/8, ssn/300, etc.)
- Maidenhead grid conversion matches algorithm in `ki7mt-ai-lab-cuda/src/io/clickhouse_loader.cpp:27-77`
- Model checkpoint includes metadata: input_dim, hidden_dim, features list, date range, sample size, phase
